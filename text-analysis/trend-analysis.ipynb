{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f692cc50-c95c-415a-afd5-31dbd08e7d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9eba031-1bd2-4475-a8dd-ef01e676e4df",
   "metadata": {},
   "source": [
    "# Trends in the albums\n",
    "\n",
    "Apart from analyzing the emotional pallete of each album I also want to extract a specific thematics - love, determination, cause which the author might want to bring into the public's awareness. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06a12e8a-9a85-4819-b931-b03ff7950562",
   "metadata": {},
   "outputs": [],
   "source": [
    "songs = pd.read_csv('../data/results/processed_lyrics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9edd3a2b-c079-42f4-8ac8-8306e4dc0da0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>album</th>\n",
       "      <th>song</th>\n",
       "      <th>words</th>\n",
       "      <th>joined_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.TTPD</td>\n",
       "      <td>HowDidItEnd</td>\n",
       "      <td>['hereby', 'conduct', 'postmortem', 'hot', 'ho...</td>\n",
       "      <td>hereby conduct postmortem hot house flower out...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.TTPD</td>\n",
       "      <td>TheBolter</td>\n",
       "      <td>['account', 'almost', 'drowned', 'six', 'frigi...</td>\n",
       "      <td>account almost drowned six frigid water confir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.TTPD</td>\n",
       "      <td>Peter</td>\n",
       "      <td>['forgive', 'peter', 'lost', 'fearless', 'lead...</td>\n",
       "      <td>forgive peter lost fearless leader closet like...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.TTPD</td>\n",
       "      <td>imgonnagetyouback</td>\n",
       "      <td>['lilac', 'short', 'skirt', 'one', 'fit', 'lik...</td>\n",
       "      <td>lilac short skirt one fit like skin research k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.TTPD</td>\n",
       "      <td>DownBad</td>\n",
       "      <td>['really', 'beam', 'cloud', 'sparkling', 'dust...</td>\n",
       "      <td>really beam cloud sparkling dust experiment te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>7.Lover</td>\n",
       "      <td>MissAmericanaTheHeartbreakPrince</td>\n",
       "      <td>['know', 'adore', \"i'm\", 'crazier', '16', 'los...</td>\n",
       "      <td>know adore i'm crazier 16 lost film scene wavi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>7.Lover</td>\n",
       "      <td>CruelSummer</td>\n",
       "      <td>['fever', 'dream', 'high', 'quiet', 'night', '...</td>\n",
       "      <td>fever dream high quiet night know caught oh ri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>7.Lover</td>\n",
       "      <td>LondonBoy</td>\n",
       "      <td>['go', \"drivin'\", 'scooter', 'uh', 'know', \"'r...</td>\n",
       "      <td>go drivin' scooter uh know 'round london oh i'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>7.Lover</td>\n",
       "      <td>FalseGod</td>\n",
       "      <td>['crazy', 'think', 'crazy', 'think', 'could', ...</td>\n",
       "      <td>crazy think crazy think could work remember sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>7.Lover</td>\n",
       "      <td>IThinkHeKnows</td>\n",
       "      <td>['think', 'know', 'footprint', 'sidewalk', 'le...</td>\n",
       "      <td>think know footprint sidewalk lead can't stop ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>242 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       album                              song  \\\n",
       "0    11.TTPD                       HowDidItEnd   \n",
       "1    11.TTPD                         TheBolter   \n",
       "2    11.TTPD                             Peter   \n",
       "3    11.TTPD                 imgonnagetyouback   \n",
       "4    11.TTPD                           DownBad   \n",
       "..       ...                               ...   \n",
       "237  7.Lover  MissAmericanaTheHeartbreakPrince   \n",
       "238  7.Lover                       CruelSummer   \n",
       "239  7.Lover                         LondonBoy   \n",
       "240  7.Lover                          FalseGod   \n",
       "241  7.Lover                     IThinkHeKnows   \n",
       "\n",
       "                                                 words  \\\n",
       "0    ['hereby', 'conduct', 'postmortem', 'hot', 'ho...   \n",
       "1    ['account', 'almost', 'drowned', 'six', 'frigi...   \n",
       "2    ['forgive', 'peter', 'lost', 'fearless', 'lead...   \n",
       "3    ['lilac', 'short', 'skirt', 'one', 'fit', 'lik...   \n",
       "4    ['really', 'beam', 'cloud', 'sparkling', 'dust...   \n",
       "..                                                 ...   \n",
       "237  ['know', 'adore', \"i'm\", 'crazier', '16', 'los...   \n",
       "238  ['fever', 'dream', 'high', 'quiet', 'night', '...   \n",
       "239  ['go', \"drivin'\", 'scooter', 'uh', 'know', \"'r...   \n",
       "240  ['crazy', 'think', 'crazy', 'think', 'could', ...   \n",
       "241  ['think', 'know', 'footprint', 'sidewalk', 'le...   \n",
       "\n",
       "                                          joined_words  \n",
       "0    hereby conduct postmortem hot house flower out...  \n",
       "1    account almost drowned six frigid water confir...  \n",
       "2    forgive peter lost fearless leader closet like...  \n",
       "3    lilac short skirt one fit like skin research k...  \n",
       "4    really beam cloud sparkling dust experiment te...  \n",
       "..                                                 ...  \n",
       "237  know adore i'm crazier 16 lost film scene wavi...  \n",
       "238  fever dream high quiet night know caught oh ri...  \n",
       "239  go drivin' scooter uh know 'round london oh i'...  \n",
       "240  crazy think crazy think could work remember sa...  \n",
       "241  think know footprint sidewalk lead can't stop ...  \n",
       "\n",
       "[242 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4972843d-b321-4cdc-959d-a77a4c178a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51316110-201c-4853-97e8-d83d9a2ecb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = vectorizer.fit_transform([songs.joined_words[180]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6b0650a-0601-4b17-86d3-9e8f7d6583de",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = vectorizer.transform([songs.joined_words[180]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cda560d-295c-4b2a-a393-8ff16e6554b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_indices = scores.toarray().argsort(axis=1)[:,-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29bfd3aa-ca85-4a95-9c23-3047f448bf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words = [(vectorizer.get_feature_names_out()[i], scores[0, i]) for i in word_indices[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "980035dc-f361-4dee-be8d-55e8458ecf14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('rain', 0.12067769800636945),\n",
       " ('kissing', 0.12067769800636945),\n",
       " ('cursing', 0.12067769800636945),\n",
       " ('coming', 0.12067769800636945),\n",
       " ('love', 0.12067769800636945),\n",
       " ('miss', 0.12067769800636945),\n",
       " ('kind', 0.12067769800636945),\n",
       " ('insane', 0.12067769800636945),\n",
       " ('name', 0.12067769800636945),\n",
       " ('2am', 0.12067769800636945),\n",
       " ('much', 0.16090359734182594),\n",
       " ('could', 0.16090359734182594),\n",
       " ('breaking', 0.16090359734182594),\n",
       " ('knew', 0.16090359734182594),\n",
       " ('feel', 0.20112949667728242),\n",
       " ('never', 0.20112949667728242),\n",
       " ('way', 0.3218071946836519),\n",
       " ('loved', 0.3218071946836519),\n",
       " ('that', 0.3218071946836519),\n",
       " ('oh', 0.40225899335456483)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f5c317-9ef5-498b-9f0c-d038225ab42c",
   "metadata": {},
   "source": [
    "Now lets group the songs by album and get the top 20 songs for each album. Then we are going to save this data in a new dataset which we are going to use later in the [Close-Up Analysis](./close-up.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ef9b55b-5ede-4477-bffd-0cae4eb181f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_songs  = songs.sort_values(by='album')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5945d2f3-5a05-4a60-ad97-48264203137d",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = sorted_songs.groupby('album')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4923bda8-0e43-403b-aebf-756396b185fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_words(album):\n",
    "    tfidf_matrix = vectorizer.fit_transform(album['joined_words'])\n",
    "    word_indices = tfidf_matrix.toarray().argsort(axis=1)[:, -20:]  # Get indices of top 20 words\n",
    "    top_words = [(vectorizer.get_feature_names_out()[i], tfidf_matrix[0, i]) for i in word_indices[0]]\n",
    "    return top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09c834cf-e5ef-44fb-bf96-8ba489ce7ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words_per_group = songs.groupby('album').apply(get_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfbb9149-89aa-4735-9418-9c0eb7bf3d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(columns=['album', 'word', 'score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9cd0f752-b0d6-4d5d-aa61-badcf4595f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "for album , top_words in top_words_per_group.items():\n",
    "    for word, score in top_words:\n",
    "        result = result.append({'album': album, 'word': word, 'score': score}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28d949c0-61e0-4b19-a406-0932d42e204e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>album</th>\n",
       "      <th>word</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.TaylorSwift</td>\n",
       "      <td>time</td>\n",
       "      <td>0.128101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.TaylorSwift</td>\n",
       "      <td>who</td>\n",
       "      <td>0.139300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.TaylorSwift</td>\n",
       "      <td>old</td>\n",
       "      <td>0.139300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.TaylorSwift</td>\n",
       "      <td>concerned</td>\n",
       "      <td>0.147523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.TaylorSwift</td>\n",
       "      <td>far</td>\n",
       "      <td>0.147523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>9.Evermore</td>\n",
       "      <td>taken</td>\n",
       "      <td>0.221970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>9.Evermore</td>\n",
       "      <td>could</td>\n",
       "      <td>0.230512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>9.Evermore</td>\n",
       "      <td>even</td>\n",
       "      <td>0.253596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>9.Evermore</td>\n",
       "      <td>road</td>\n",
       "      <td>0.253596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>9.Evermore</td>\n",
       "      <td>call</td>\n",
       "      <td>0.279344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>220 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             album       word     score\n",
       "0    1.TaylorSwift       time  0.128101\n",
       "1    1.TaylorSwift        who  0.139300\n",
       "2    1.TaylorSwift        old  0.139300\n",
       "3    1.TaylorSwift  concerned  0.147523\n",
       "4    1.TaylorSwift        far  0.147523\n",
       "..             ...        ...       ...\n",
       "215     9.Evermore      taken  0.221970\n",
       "216     9.Evermore      could  0.230512\n",
       "217     9.Evermore       even  0.253596\n",
       "218     9.Evermore       road  0.253596\n",
       "219     9.Evermore       call  0.279344\n",
       "\n",
       "[220 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22090471-c37d-4576-8fe9-34da09c4bd11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>album</th>\n",
       "      <th>word</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>10.Midnights</td>\n",
       "      <td>think</td>\n",
       "      <td>0.068835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>10.Midnights</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>0.074407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>10.Midnights</td>\n",
       "      <td>sunshine</td>\n",
       "      <td>0.102405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10.Midnights</td>\n",
       "      <td>except</td>\n",
       "      <td>0.102405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>10.Midnights</td>\n",
       "      <td>full</td>\n",
       "      <td>0.102405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>10.Midnights</td>\n",
       "      <td>haunted</td>\n",
       "      <td>0.102405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>10.Midnights</td>\n",
       "      <td>guess</td>\n",
       "      <td>0.102405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>10.Midnights</td>\n",
       "      <td>like</td>\n",
       "      <td>0.137502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>10.Midnights</td>\n",
       "      <td>stayed</td>\n",
       "      <td>0.180031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>10.Midnights</td>\n",
       "      <td>bride</td>\n",
       "      <td>0.180031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>10.Midnights</td>\n",
       "      <td>pain</td>\n",
       "      <td>0.180031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>10.Midnights</td>\n",
       "      <td>rain</td>\n",
       "      <td>0.180031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>10.Midnights</td>\n",
       "      <td>making</td>\n",
       "      <td>0.204809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>10.Midnights</td>\n",
       "      <td>comfortable</td>\n",
       "      <td>0.204809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>10.Midnights</td>\n",
       "      <td>name</td>\n",
       "      <td>0.204809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>10.Midnights</td>\n",
       "      <td>changed</td>\n",
       "      <td>0.204809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>10.Midnights</td>\n",
       "      <td>chasing</td>\n",
       "      <td>0.204809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>10.Midnights</td>\n",
       "      <td>fame</td>\n",
       "      <td>0.204809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>10.Midnights</td>\n",
       "      <td>midnight</td>\n",
       "      <td>0.334829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>10.Midnights</td>\n",
       "      <td>wanted</td>\n",
       "      <td>0.568574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           album         word     score\n",
       "20  10.Midnights        think  0.068835\n",
       "21  10.Midnights    sometimes  0.074407\n",
       "22  10.Midnights     sunshine  0.102405\n",
       "23  10.Midnights       except  0.102405\n",
       "24  10.Midnights         full  0.102405\n",
       "25  10.Midnights      haunted  0.102405\n",
       "26  10.Midnights        guess  0.102405\n",
       "27  10.Midnights         like  0.137502\n",
       "28  10.Midnights       stayed  0.180031\n",
       "29  10.Midnights        bride  0.180031\n",
       "30  10.Midnights         pain  0.180031\n",
       "31  10.Midnights         rain  0.180031\n",
       "32  10.Midnights       making  0.204809\n",
       "33  10.Midnights  comfortable  0.204809\n",
       "34  10.Midnights         name  0.204809\n",
       "35  10.Midnights      changed  0.204809\n",
       "36  10.Midnights      chasing  0.204809\n",
       "37  10.Midnights         fame  0.204809\n",
       "38  10.Midnights     midnight  0.334829\n",
       "39  10.Midnights       wanted  0.568574"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[(result.album == '10.Midnights')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "865048a7-bea9-4fb1-aa93-94ba47eaa8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('../data/results/album-thematics',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
