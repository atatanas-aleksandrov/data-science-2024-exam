{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00452804-d36f-4c05-b5bc-c30eec4cf1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import nltk, os, glob, re\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd78bda5-3058-449c-8983-33c11b99fd75",
   "metadata": {},
   "source": [
    "# Lyrics Read and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc155563-c469-4515-8ac9-46eb747b3fa1",
   "metadata": {},
   "source": [
    "## Workflow: In this notebook I will read the lyrics into a dataframe and prepare it for work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0878e1df-981f-4e71-bab2-5f15463361ee",
   "metadata": {},
   "source": [
    "## Information about the data: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122699c8-e411-4b71-a039-643877feb7cc",
   "metadata": {},
   "source": [
    "## Reading and exploring the files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55acb9a0-6c33-41c3-9400-644d9ffdb4b1",
   "metadata": {},
   "source": [
    "The approach I have chosen is to make a big dataset with all lyrics so I can have an initial exploration and and clean up. After that I will decide if I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "389874c4-3fd9-4856-8ee5-aee2cdc75254",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data_frame(path):\n",
    "    \"\"\"\n",
    "    The following function will go through the albums directory and its subdirectories,\n",
    "    collect the songs lyrics, the song and album name they belong to and create a \n",
    "    dataframe, which we then are going to use to analyze the lyrics.\n",
    "    \"\"\"\n",
    "    data  = []\n",
    "    for album_dir in glob.glob(os.path.join(path, \"*\")):\n",
    "        album_name = os.path.basename(album_dir)\n",
    "        for song_file in glob.glob(os.path.join(album_dir, \"*.txt\")):\n",
    "            song_name = os.path.basename(song_file)\n",
    "            with open(song_file, \"r\") as f:\n",
    "                lyrics = f.read()\n",
    "            data.append((album_name, song_name, lyrics))\n",
    "\n",
    "    df = pd.DataFrame(data, columns=[\"album\", \"song\", \"lyrics\"])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e9d0fef-7dcb-4285-9d49-bef4f2b9ea3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "songs = make_data_frame(\"../data/albums\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29747f48-168b-48e0-ade3-95dee7abf7c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>album</th>\n",
       "      <th>song</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.THETORTUREDPOETSDEPARTMENT_THEANTHOLOGY</td>\n",
       "      <td>HowDidItEnd_.txt</td>\n",
       "      <td>137 ContributorsTranslationsPortuguêsEspañolال...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.THETORTUREDPOETSDEPARTMENT_THEANTHOLOGY</td>\n",
       "      <td>TheBolter.txt</td>\n",
       "      <td>93 ContributorsTranslationsالعربيةFrançaisفارس...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.THETORTUREDPOETSDEPARTMENT_THEANTHOLOGY</td>\n",
       "      <td>Peter.txt</td>\n",
       "      <td>95 ContributorsTranslationsEspañolFrançaisDeut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.THETORTUREDPOETSDEPARTMENT_THEANTHOLOGY</td>\n",
       "      <td>imgonnagetyouback.txt</td>\n",
       "      <td>97 ContributorsTranslationsEspañolالعربيةFranç...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.THETORTUREDPOETSDEPARTMENT_THEANTHOLOGY</td>\n",
       "      <td>DownBad.txt</td>\n",
       "      <td>117 ContributorsTranslationsTürkçePortuguêsEsp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>7.Lover</td>\n",
       "      <td>MissAmericana_TheHeartbreakPrince.txt</td>\n",
       "      <td>111 ContributorsTranslationsEnglishHrvatskiPor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>7.Lover</td>\n",
       "      <td>CruelSummer.txt</td>\n",
       "      <td>166 ContributorsTranslationsTürkçeEspañolHrvat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>7.Lover</td>\n",
       "      <td>LondonBoy.txt</td>\n",
       "      <td>106 ContributorsTranslationsEspañolHrvatskiPor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>7.Lover</td>\n",
       "      <td>FalseGod.txt</td>\n",
       "      <td>91 ContributorsTranslationsTürkçeEspañolHrvats...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>7.Lover</td>\n",
       "      <td>IThinkHeKnows.txt</td>\n",
       "      <td>73 ContributorsTranslationsEspañolСрпскиPortug...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>243 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          album  \\\n",
       "0    11.THETORTUREDPOETSDEPARTMENT_THEANTHOLOGY   \n",
       "1    11.THETORTUREDPOETSDEPARTMENT_THEANTHOLOGY   \n",
       "2    11.THETORTUREDPOETSDEPARTMENT_THEANTHOLOGY   \n",
       "3    11.THETORTUREDPOETSDEPARTMENT_THEANTHOLOGY   \n",
       "4    11.THETORTUREDPOETSDEPARTMENT_THEANTHOLOGY   \n",
       "..                                          ...   \n",
       "238                                     7.Lover   \n",
       "239                                     7.Lover   \n",
       "240                                     7.Lover   \n",
       "241                                     7.Lover   \n",
       "242                                     7.Lover   \n",
       "\n",
       "                                      song  \\\n",
       "0                         HowDidItEnd_.txt   \n",
       "1                            TheBolter.txt   \n",
       "2                                Peter.txt   \n",
       "3                    imgonnagetyouback.txt   \n",
       "4                              DownBad.txt   \n",
       "..                                     ...   \n",
       "238  MissAmericana_TheHeartbreakPrince.txt   \n",
       "239                        CruelSummer.txt   \n",
       "240                          LondonBoy.txt   \n",
       "241                           FalseGod.txt   \n",
       "242                      IThinkHeKnows.txt   \n",
       "\n",
       "                                                lyrics  \n",
       "0    137 ContributorsTranslationsPortuguêsEspañolال...  \n",
       "1    93 ContributorsTranslationsالعربيةFrançaisفارس...  \n",
       "2    95 ContributorsTranslationsEspañolFrançaisDeut...  \n",
       "3    97 ContributorsTranslationsEspañolالعربيةFranç...  \n",
       "4    117 ContributorsTranslationsTürkçePortuguêsEsp...  \n",
       "..                                                 ...  \n",
       "238  111 ContributorsTranslationsEnglishHrvatskiPor...  \n",
       "239  166 ContributorsTranslationsTürkçeEspañolHrvat...  \n",
       "240  106 ContributorsTranslationsEspañolHrvatskiPor...  \n",
       "241  91 ContributorsTranslationsTürkçeEspañolHrvats...  \n",
       "242  73 ContributorsTranslationsEspañolСрпскиPortug...  \n",
       "\n",
       "[243 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b7835d-491b-45d0-8cb1-a5f57543a51d",
   "metadata": {},
   "source": [
    "After loading the data successfully it's time to clean it up."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e081af3b-a38d-4b09-8209-f6df01c11e23",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4690760-f408-4b52-9aee-6cbdba69c8cc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "scrolled": true
   },
   "source": [
    "### Cleaning the album titles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb787368-ad26-4c87-805f-0625c08ead50",
   "metadata": {},
   "source": [
    "Albums with long names such as `The Tortured Poets Department` will get an abbreviation like `TTPD`. Empty spaces and decapitalized albums will be fixed. Since those are single cases there would not be any need for function implementation and will fix them by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "704b615d-4c66-4ad9-a6ba-af38907d041d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['11.THETORTUREDPOETSDEPARTMENT_THEANTHOLOGY', '4.Red',\n",
       "       '10.Midnights', '5.1989', '9. evermore', '6.Reputation',\n",
       "       '1.TaylorSwift', '3.SpeakNow', '2.Fearless', '8.Folklore',\n",
       "       '7.Lover'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs.album.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0df99322-0b3e-447b-93aa-a9aaa478585f",
   "metadata": {},
   "outputs": [],
   "source": [
    "songs.album[songs.album == \"11.THETORTUREDPOETSDEPARTMENT_THEANTHOLOGY\"] = \"11.TTPD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "244e5ec8-bac3-4925-92d5-ff9832bba5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "songs.album[songs.album == \"9. evermore\"] = \"9.Evermore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c48dd81-0183-4091-a21a-be77a5a5a32f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['11.TTPD', '4.Red', '10.Midnights', '5.1989', '9.Evermore',\n",
       "       '6.Reputation', '1.TaylorSwift', '3.SpeakNow', '2.Fearless',\n",
       "       '8.Folklore', '7.Lover'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs.album.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb872aa-1404-447a-9990-9fb5c8edba56",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Cleaning the song titles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786c598d-6eab-4bd2-a41d-d64563e3d0dc",
   "metadata": {},
   "source": [
    "I will trim the '.txt' from the names under song column. There are songs with suffixes like `_From_The_Vault_` `_Taylors_Version_` which are also redundant in that case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "909d035e-5ae1-4f92-a518-a177cf4bf65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_song_name(song, characters = [\"_\",\".txt\"], patterns=[\"TaylorsVersion\",\"FromTheVault\"], replacement = \"\"):\n",
    "    \n",
    "    for character in characters:\n",
    "        song = song.replace(character, replacement)\n",
    "\n",
    "    for pattern in patterns:\n",
    "        song = re.sub(pattern, replacement, song)\n",
    "\n",
    "    return song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ad88ac3-dd3f-45bc-9050-77ca4d8f01d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "songs.song = songs.song.apply(clean_song_name).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7955705-50dc-4f53-a767-23ead67ab41d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>album</th>\n",
       "      <th>song</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.TTPD</td>\n",
       "      <td>HowDidItEnd</td>\n",
       "      <td>137 ContributorsTranslationsPortuguêsEspañolال...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.TTPD</td>\n",
       "      <td>TheBolter</td>\n",
       "      <td>93 ContributorsTranslationsالعربيةFrançaisفارس...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.TTPD</td>\n",
       "      <td>Peter</td>\n",
       "      <td>95 ContributorsTranslationsEspañolFrançaisDeut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.TTPD</td>\n",
       "      <td>imgonnagetyouback</td>\n",
       "      <td>97 ContributorsTranslationsEspañolالعربيةFranç...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.TTPD</td>\n",
       "      <td>DownBad</td>\n",
       "      <td>117 ContributorsTranslationsTürkçePortuguêsEsp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>7.Lover</td>\n",
       "      <td>MissAmericanaTheHeartbreakPrince</td>\n",
       "      <td>111 ContributorsTranslationsEnglishHrvatskiPor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>7.Lover</td>\n",
       "      <td>CruelSummer</td>\n",
       "      <td>166 ContributorsTranslationsTürkçeEspañolHrvat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>7.Lover</td>\n",
       "      <td>LondonBoy</td>\n",
       "      <td>106 ContributorsTranslationsEspañolHrvatskiPor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>7.Lover</td>\n",
       "      <td>FalseGod</td>\n",
       "      <td>91 ContributorsTranslationsTürkçeEspañolHrvats...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>7.Lover</td>\n",
       "      <td>IThinkHeKnows</td>\n",
       "      <td>73 ContributorsTranslationsEspañolСрпскиPortug...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>243 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       album                              song  \\\n",
       "0    11.TTPD                       HowDidItEnd   \n",
       "1    11.TTPD                         TheBolter   \n",
       "2    11.TTPD                             Peter   \n",
       "3    11.TTPD                 imgonnagetyouback   \n",
       "4    11.TTPD                           DownBad   \n",
       "..       ...                               ...   \n",
       "238  7.Lover  MissAmericanaTheHeartbreakPrince   \n",
       "239  7.Lover                       CruelSummer   \n",
       "240  7.Lover                         LondonBoy   \n",
       "241  7.Lover                          FalseGod   \n",
       "242  7.Lover                     IThinkHeKnows   \n",
       "\n",
       "                                                lyrics  \n",
       "0    137 ContributorsTranslationsPortuguêsEspañolال...  \n",
       "1    93 ContributorsTranslationsالعربيةFrançaisفارس...  \n",
       "2    95 ContributorsTranslationsEspañolFrançaisDeut...  \n",
       "3    97 ContributorsTranslationsEspañolالعربيةFranç...  \n",
       "4    117 ContributorsTranslationsTürkçePortuguêsEsp...  \n",
       "..                                                 ...  \n",
       "238  111 ContributorsTranslationsEnglishHrvatskiPor...  \n",
       "239  166 ContributorsTranslationsTürkçeEspañolHrvat...  \n",
       "240  106 ContributorsTranslationsEspañolHrvatskiPor...  \n",
       "241  91 ContributorsTranslationsTürkçeEspañolHrvats...  \n",
       "242  73 ContributorsTranslationsEspañolСрпскиPortug...  \n",
       "\n",
       "[243 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709d398c-e982-44e5-b248-5b2980fcd90e",
   "metadata": {},
   "source": [
    "### Cleaning the lyrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce1dffe-89f3-4d54-bf98-9f4b2176de11",
   "metadata": {},
   "source": [
    "First things first I want to get rid of the precredits : \"137 ContributorsTranslationsPortuguêsEspañolال...\" since they do not carry any significant information about tendencies, trends or sentiment. Then I want to remove everything in [] like `[Intro]`, `[Verse 1]` and so on, commas and parenthesies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5551b409-95de-49e5-b998-404670d1c06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_credits(text):\n",
    "    \"\"\"\n",
    "    Removes everything before and including \"Lyrics\" from a given text.\n",
    "    \"\"\"\n",
    "\n",
    "    match = re.search(r\"Lyrics\", text, re.IGNORECASE)\n",
    "    if match:\n",
    "        return text[match.end():]\n",
    "    else:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "040b5a85-82ed-4e8b-a61e-2afde0a94ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "songs.lyrics = songs.lyrics.apply(remove_credits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ecf72952-371a-4637-b4b2-4d3326a10b73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>album</th>\n",
       "      <th>song</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.TTPD</td>\n",
       "      <td>HowDidItEnd</td>\n",
       "      <td>[Intro]\\n(Uh-oh, uh-oh)\\n\\n[Verse 1]\\nWe hereb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.TTPD</td>\n",
       "      <td>TheBolter</td>\n",
       "      <td>[Verse 1]\\nBy all accounts, she almost drowned...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.TTPD</td>\n",
       "      <td>Peter</td>\n",
       "      <td>[Verse 1]\\nForgive me, Peter\\nMy lost fearless...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.TTPD</td>\n",
       "      <td>imgonnagetyouback</td>\n",
       "      <td>[Intro]\\nYeah\\n\\n[Verse 1]\\nLilac short skirt,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.TTPD</td>\n",
       "      <td>DownBad</td>\n",
       "      <td>[Verse 1]\\nDid you really beam me up\\nIn a clo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>7.Lover</td>\n",
       "      <td>MissAmericanaTheHeartbreakPrince</td>\n",
       "      <td>[Verse 1]\\nYou know I adore you, I'm crazier f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>7.Lover</td>\n",
       "      <td>CruelSummer</td>\n",
       "      <td>[Intro]\\n(Yeah, yeah, yeah, yeah)\\n\\n[Verse 1]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>7.Lover</td>\n",
       "      <td>LondonBoy</td>\n",
       "      <td>[Intro: Idris Elba &amp; James Corden]\\nWe can go ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>7.Lover</td>\n",
       "      <td>FalseGod</td>\n",
       "      <td>[Verse 1]\\nWe were crazy to think\\nCrazy to th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>7.Lover</td>\n",
       "      <td>IThinkHeKnows</td>\n",
       "      <td>[Verse 1]\\nI think he knows\\nHis footprints on...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>243 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       album                              song  \\\n",
       "0    11.TTPD                       HowDidItEnd   \n",
       "1    11.TTPD                         TheBolter   \n",
       "2    11.TTPD                             Peter   \n",
       "3    11.TTPD                 imgonnagetyouback   \n",
       "4    11.TTPD                           DownBad   \n",
       "..       ...                               ...   \n",
       "238  7.Lover  MissAmericanaTheHeartbreakPrince   \n",
       "239  7.Lover                       CruelSummer   \n",
       "240  7.Lover                         LondonBoy   \n",
       "241  7.Lover                          FalseGod   \n",
       "242  7.Lover                     IThinkHeKnows   \n",
       "\n",
       "                                                lyrics  \n",
       "0    [Intro]\\n(Uh-oh, uh-oh)\\n\\n[Verse 1]\\nWe hereb...  \n",
       "1    [Verse 1]\\nBy all accounts, she almost drowned...  \n",
       "2    [Verse 1]\\nForgive me, Peter\\nMy lost fearless...  \n",
       "3    [Intro]\\nYeah\\n\\n[Verse 1]\\nLilac short skirt,...  \n",
       "4    [Verse 1]\\nDid you really beam me up\\nIn a clo...  \n",
       "..                                                 ...  \n",
       "238  [Verse 1]\\nYou know I adore you, I'm crazier f...  \n",
       "239  [Intro]\\n(Yeah, yeah, yeah, yeah)\\n\\n[Verse 1]...  \n",
       "240  [Intro: Idris Elba & James Corden]\\nWe can go ...  \n",
       "241  [Verse 1]\\nWe were crazy to think\\nCrazy to th...  \n",
       "242  [Verse 1]\\nI think he knows\\nHis footprints on...  \n",
       "\n",
       "[243 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff076214-26f1-4e5e-a281-8406381be6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_lyric_tags(text, patterns = [r\"(\\[.*?\\])\",\"\\d{1,10}Embed\"]):\n",
    "    for pattern in patterns:\n",
    "        text = re.sub(pattern,\"\",text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f219eb4-417f-4ad4-b2c7-b28dbcb6a8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "songs.lyrics  = songs.lyrics.apply(remove_lyric_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "903e15c1-2f6f-4901-abe3-2c0ef5e6b4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "songs[\"words\"] = songs.lyrics.str.split('\\s+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "591418f0-ffeb-4641-b4a7-4612e550fe3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'hi \\na'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c03ab84c-ec1f-4647-9586-5e435d2e9e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "delimeters = \"[\\s+\\n]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00d486f8-3879-47c6-b55c-04ae4cfd85c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi', '', 'a']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.split(delimeters, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8633f62f-1be6-4ab9-9a28-f216e790ced7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>album</th>\n",
       "      <th>song</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.TTPD</td>\n",
       "      <td>HowDidItEnd</td>\n",
       "      <td>\\n(Uh-oh, uh-oh)\\n\\n\\nWe hereby conduct this p...</td>\n",
       "      <td>[, (Uh-oh,, uh-oh), We, hereby, conduct, this,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.TTPD</td>\n",
       "      <td>TheBolter</td>\n",
       "      <td>\\nBy all accounts, she almost drowned\\nWhen sh...</td>\n",
       "      <td>[, By, all, accounts,, she, almost, drowned, W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.TTPD</td>\n",
       "      <td>Peter</td>\n",
       "      <td>\\nForgive me, Peter\\nMy lost fearless leader\\n...</td>\n",
       "      <td>[, Forgive, me,, Peter, My, lost, fearless, le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.TTPD</td>\n",
       "      <td>imgonnagetyouback</td>\n",
       "      <td>\\nYeah\\n\\n\\nLilac short skirt, the one that fi...</td>\n",
       "      <td>[, Yeah, Lilac, short, skirt,, the, one, that,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.TTPD</td>\n",
       "      <td>DownBad</td>\n",
       "      <td>\\nDid you really beam me up\\nIn a cloud of spa...</td>\n",
       "      <td>[, Did, you, really, beam, me, up, In, a, clou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>7.Lover</td>\n",
       "      <td>MissAmericanaTheHeartbreakPrince</td>\n",
       "      <td>\\nYou know I adore you, I'm crazier for you\\nT...</td>\n",
       "      <td>[, You, know, I, adore, you,, I'm, crazier, fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>7.Lover</td>\n",
       "      <td>CruelSummer</td>\n",
       "      <td>\\n(Yeah, yeah, yeah, yeah)\\n\\n\\nFever dream hi...</td>\n",
       "      <td>[, (Yeah,, yeah,, yeah,, yeah), Fever, dream, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>7.Lover</td>\n",
       "      <td>LondonBoy</td>\n",
       "      <td>\\nWe can go drivin' in, on my scooter\\nUh, you...</td>\n",
       "      <td>[, We, can, go, drivin', in,, on, my, scooter,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>7.Lover</td>\n",
       "      <td>FalseGod</td>\n",
       "      <td>\\nWe were crazy to think\\nCrazy to think that ...</td>\n",
       "      <td>[, We, were, crazy, to, think, Crazy, to, thin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>7.Lover</td>\n",
       "      <td>IThinkHeKnows</td>\n",
       "      <td>\\nI think he knows\\nHis footprints on the side...</td>\n",
       "      <td>[, I, think, he, knows, His, footprints, on, t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>243 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       album                              song  \\\n",
       "0    11.TTPD                       HowDidItEnd   \n",
       "1    11.TTPD                         TheBolter   \n",
       "2    11.TTPD                             Peter   \n",
       "3    11.TTPD                 imgonnagetyouback   \n",
       "4    11.TTPD                           DownBad   \n",
       "..       ...                               ...   \n",
       "238  7.Lover  MissAmericanaTheHeartbreakPrince   \n",
       "239  7.Lover                       CruelSummer   \n",
       "240  7.Lover                         LondonBoy   \n",
       "241  7.Lover                          FalseGod   \n",
       "242  7.Lover                     IThinkHeKnows   \n",
       "\n",
       "                                                lyrics  \\\n",
       "0    \\n(Uh-oh, uh-oh)\\n\\n\\nWe hereby conduct this p...   \n",
       "1    \\nBy all accounts, she almost drowned\\nWhen sh...   \n",
       "2    \\nForgive me, Peter\\nMy lost fearless leader\\n...   \n",
       "3    \\nYeah\\n\\n\\nLilac short skirt, the one that fi...   \n",
       "4    \\nDid you really beam me up\\nIn a cloud of spa...   \n",
       "..                                                 ...   \n",
       "238  \\nYou know I adore you, I'm crazier for you\\nT...   \n",
       "239  \\n(Yeah, yeah, yeah, yeah)\\n\\n\\nFever dream hi...   \n",
       "240  \\nWe can go drivin' in, on my scooter\\nUh, you...   \n",
       "241  \\nWe were crazy to think\\nCrazy to think that ...   \n",
       "242  \\nI think he knows\\nHis footprints on the side...   \n",
       "\n",
       "                                                 words  \n",
       "0    [, (Uh-oh,, uh-oh), We, hereby, conduct, this,...  \n",
       "1    [, By, all, accounts,, she, almost, drowned, W...  \n",
       "2    [, Forgive, me,, Peter, My, lost, fearless, le...  \n",
       "3    [, Yeah, Lilac, short, skirt,, the, one, that,...  \n",
       "4    [, Did, you, really, beam, me, up, In, a, clou...  \n",
       "..                                                 ...  \n",
       "238  [, You, know, I, adore, you,, I'm, crazier, fo...  \n",
       "239  [, (Yeah,, yeah,, yeah,, yeah), Fever, dream, ...  \n",
       "240  [, We, can, go, drivin', in,, on, my, scooter,...  \n",
       "241  [, We, were, crazy, to, think, Crazy, to, thin...  \n",
       "242  [, I, think, he, knows, His, footprints, on, t...  \n",
       "\n",
       "[243 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed3e2cb-f50b-42a6-a152-0de21c120cad",
   "metadata": {},
   "source": [
    "It seems we have an outlier with length 0 which might cause exceptions later "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b9ecf647-eb19-4c0e-aaf3-763ce2d58d08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>album</th>\n",
       "      <th>song</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [album, song, lyrics, words]\n",
       "Index: []"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs[songs.words.str.len() == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b9cd7ca1-0445-45b9-9aa9-134d35499c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "songs.drop(133,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4aca1f9a-728a-495e-a6d6-afedac1c0283",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(words,characters = [\":\",\",\",\"(\",\")\",\"-\",\"?\",\"!\",\"\\\"\"], patterns = [r\"(\\[.*?\\])\",\"\\d{1,10}Embed\"], replacement = \"\"):\n",
    "    \"\"\"\n",
    "    Removes everything before and including the word \"Lyrics\" in a given text. \n",
    "    \"\"\"\n",
    "    cleaned_words = words.copy()\n",
    "\n",
    "    for character in characters:\n",
    "\n",
    "        cleaned_words = [word.replace(character,replacement) for word in cleaned_words]\n",
    "\n",
    "    cleaned_words = [word.replace(\"\\n\",\" \") for word in cleaned_words]\n",
    "\n",
    "    for pattern in patterns:\n",
    "        cleaned_words = [re.sub(pattern,replacement,word) for word in cleaned_words]\n",
    "\n",
    "    cleaned_words = [word for word in cleaned_words if word != \"\"]\n",
    "\n",
    "    return cleaned_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1717528d-0d5a-4616-a985-ce13903987cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "songs.words = songs.words.apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a909093b-b33f-4108-a0aa-bd152c4c305e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>album</th>\n",
       "      <th>song</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.TTPD</td>\n",
       "      <td>HowDidItEnd</td>\n",
       "      <td>\\n(Uh-oh, uh-oh)\\n\\n\\nWe hereby conduct this p...</td>\n",
       "      <td>[Uhoh, uhoh, We, hereby, conduct, this, postmo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.TTPD</td>\n",
       "      <td>TheBolter</td>\n",
       "      <td>\\nBy all accounts, she almost drowned\\nWhen sh...</td>\n",
       "      <td>[By, all, accounts, she, almost, drowned, When...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.TTPD</td>\n",
       "      <td>Peter</td>\n",
       "      <td>\\nForgive me, Peter\\nMy lost fearless leader\\n...</td>\n",
       "      <td>[Forgive, me, Peter, My, lost, fearless, leade...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.TTPD</td>\n",
       "      <td>imgonnagetyouback</td>\n",
       "      <td>\\nYeah\\n\\n\\nLilac short skirt, the one that fi...</td>\n",
       "      <td>[Yeah, Lilac, short, skirt, the, one, that, fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.TTPD</td>\n",
       "      <td>DownBad</td>\n",
       "      <td>\\nDid you really beam me up\\nIn a cloud of spa...</td>\n",
       "      <td>[Did, you, really, beam, me, up, In, a, cloud,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>7.Lover</td>\n",
       "      <td>MissAmericanaTheHeartbreakPrince</td>\n",
       "      <td>\\nYou know I adore you, I'm crazier for you\\nT...</td>\n",
       "      <td>[You, know, I, adore, you, I'm, crazier, for, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>7.Lover</td>\n",
       "      <td>CruelSummer</td>\n",
       "      <td>\\n(Yeah, yeah, yeah, yeah)\\n\\n\\nFever dream hi...</td>\n",
       "      <td>[Yeah, yeah, yeah, yeah, Fever, dream, high, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>7.Lover</td>\n",
       "      <td>LondonBoy</td>\n",
       "      <td>\\nWe can go drivin' in, on my scooter\\nUh, you...</td>\n",
       "      <td>[We, can, go, drivin', in, on, my, scooter, Uh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>7.Lover</td>\n",
       "      <td>FalseGod</td>\n",
       "      <td>\\nWe were crazy to think\\nCrazy to think that ...</td>\n",
       "      <td>[We, were, crazy, to, think, Crazy, to, think,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>7.Lover</td>\n",
       "      <td>IThinkHeKnows</td>\n",
       "      <td>\\nI think he knows\\nHis footprints on the side...</td>\n",
       "      <td>[I, think, he, knows, His, footprints, on, the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>242 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       album                              song  \\\n",
       "0    11.TTPD                       HowDidItEnd   \n",
       "1    11.TTPD                         TheBolter   \n",
       "2    11.TTPD                             Peter   \n",
       "3    11.TTPD                 imgonnagetyouback   \n",
       "4    11.TTPD                           DownBad   \n",
       "..       ...                               ...   \n",
       "238  7.Lover  MissAmericanaTheHeartbreakPrince   \n",
       "239  7.Lover                       CruelSummer   \n",
       "240  7.Lover                         LondonBoy   \n",
       "241  7.Lover                          FalseGod   \n",
       "242  7.Lover                     IThinkHeKnows   \n",
       "\n",
       "                                                lyrics  \\\n",
       "0    \\n(Uh-oh, uh-oh)\\n\\n\\nWe hereby conduct this p...   \n",
       "1    \\nBy all accounts, she almost drowned\\nWhen sh...   \n",
       "2    \\nForgive me, Peter\\nMy lost fearless leader\\n...   \n",
       "3    \\nYeah\\n\\n\\nLilac short skirt, the one that fi...   \n",
       "4    \\nDid you really beam me up\\nIn a cloud of spa...   \n",
       "..                                                 ...   \n",
       "238  \\nYou know I adore you, I'm crazier for you\\nT...   \n",
       "239  \\n(Yeah, yeah, yeah, yeah)\\n\\n\\nFever dream hi...   \n",
       "240  \\nWe can go drivin' in, on my scooter\\nUh, you...   \n",
       "241  \\nWe were crazy to think\\nCrazy to think that ...   \n",
       "242  \\nI think he knows\\nHis footprints on the side...   \n",
       "\n",
       "                                                 words  \n",
       "0    [Uhoh, uhoh, We, hereby, conduct, this, postmo...  \n",
       "1    [By, all, accounts, she, almost, drowned, When...  \n",
       "2    [Forgive, me, Peter, My, lost, fearless, leade...  \n",
       "3    [Yeah, Lilac, short, skirt, the, one, that, fi...  \n",
       "4    [Did, you, really, beam, me, up, In, a, cloud,...  \n",
       "..                                                 ...  \n",
       "238  [You, know, I, adore, you, I'm, crazier, for, ...  \n",
       "239  [Yeah, yeah, yeah, yeah, Fever, dream, high, i...  \n",
       "240  [We, can, go, drivin', in, on, my, scooter, Uh...  \n",
       "241  [We, were, crazy, to, think, Crazy, to, think,...  \n",
       "242  [I, think, he, knows, His, footprints, on, the...  \n",
       "\n",
       "[242 rows x 4 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457f4190-b259-4c57-8347-0f3deb95b3ac",
   "metadata": {},
   "source": [
    "### Adapting the words column to be compatible for sentiment analysis.\n",
    "To make the words from the lyrics understandable to the models we are about to use certain things must be done:\n",
    "\n",
    "* Word tokenization : this is the process of splitting the lyrics string into separate strings, where each word (substring) will represent one token\n",
    "* Stop Word Filtering : Just as any other text the song lyrics contain certain words that do not hold any relevant information for the analysis. Such words are called stop - words and need to be removed from the lyrics.\n",
    "* Word Stemming/ Lemmatization: both methods are used to reduce the word to its root and remove suffixes like `-ing` etc. I chose to use lematization process simply because it is more accurate than the Stemming, where Stemming could produce words such as `runn` which is not correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e2cf417d-b2a1-4336-a11c-956544246cff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Uhoh',\n",
       " 'uhoh',\n",
       " 'We',\n",
       " 'hereby',\n",
       " 'conduct',\n",
       " 'this',\n",
       " 'postmortem',\n",
       " 'He',\n",
       " 'was',\n",
       " 'a',\n",
       " 'hot',\n",
       " 'house',\n",
       " 'flower',\n",
       " 'to',\n",
       " 'my',\n",
       " 'outdoorsman',\n",
       " 'Our',\n",
       " 'maladies',\n",
       " 'were',\n",
       " 'such',\n",
       " 'we',\n",
       " 'could',\n",
       " 'not',\n",
       " 'cure',\n",
       " 'them',\n",
       " 'And',\n",
       " 'so',\n",
       " 'a',\n",
       " 'touch',\n",
       " 'that',\n",
       " 'was',\n",
       " 'my',\n",
       " 'birthright',\n",
       " 'became',\n",
       " 'foreign',\n",
       " 'Come',\n",
       " 'one',\n",
       " 'come',\n",
       " 'all',\n",
       " \"it's\",\n",
       " \"happenin'\",\n",
       " 'again',\n",
       " 'The',\n",
       " 'empathetic',\n",
       " 'hunger',\n",
       " 'descends',\n",
       " \"We'll\",\n",
       " 'tell',\n",
       " 'no',\n",
       " 'one',\n",
       " 'except',\n",
       " 'all',\n",
       " 'of',\n",
       " 'our',\n",
       " 'friends',\n",
       " 'We',\n",
       " 'must',\n",
       " 'know',\n",
       " 'How',\n",
       " 'did',\n",
       " 'it',\n",
       " 'end',\n",
       " 'Uhoh',\n",
       " 'uhoh',\n",
       " 'We',\n",
       " 'were',\n",
       " 'blind',\n",
       " 'to',\n",
       " 'unforeseen',\n",
       " 'circumstances',\n",
       " 'We',\n",
       " 'learned',\n",
       " 'thе',\n",
       " 'right',\n",
       " 'steps',\n",
       " 'to',\n",
       " 'different',\n",
       " 'dancеs',\n",
       " 'And',\n",
       " 'fell',\n",
       " 'victim',\n",
       " 'to',\n",
       " \"interlopers'\",\n",
       " 'glances',\n",
       " 'Lost',\n",
       " 'the',\n",
       " 'game',\n",
       " 'of',\n",
       " 'chance',\n",
       " 'what',\n",
       " 'are',\n",
       " 'the',\n",
       " 'chances',\n",
       " 'Soon',\n",
       " \"they'll\",\n",
       " 'go',\n",
       " 'home',\n",
       " 'to',\n",
       " 'their',\n",
       " 'husbands',\n",
       " 'Smug',\n",
       " \"'cause\",\n",
       " 'they',\n",
       " 'know',\n",
       " 'they',\n",
       " 'can',\n",
       " 'trust',\n",
       " 'him',\n",
       " 'Then',\n",
       " 'feverishly',\n",
       " 'calling',\n",
       " 'their',\n",
       " 'cousins',\n",
       " 'See',\n",
       " 'Taylor',\n",
       " 'Swift',\n",
       " 'LiveGet',\n",
       " 'tickets',\n",
       " 'as',\n",
       " 'low',\n",
       " 'as',\n",
       " '$60You',\n",
       " 'might',\n",
       " 'also',\n",
       " 'like',\n",
       " 'Guess',\n",
       " 'who',\n",
       " 'we',\n",
       " 'ran',\n",
       " 'into',\n",
       " 'at',\n",
       " 'the',\n",
       " 'shops',\n",
       " 'Walking',\n",
       " 'in',\n",
       " 'circles',\n",
       " 'like',\n",
       " 'she',\n",
       " 'was',\n",
       " 'lost',\n",
       " \"Didn't\",\n",
       " 'you',\n",
       " 'hear',\n",
       " 'They',\n",
       " 'called',\n",
       " 'it',\n",
       " 'all',\n",
       " 'off',\n",
       " 'One',\n",
       " 'gasp',\n",
       " 'and',\n",
       " 'then',\n",
       " 'How',\n",
       " 'did',\n",
       " 'it',\n",
       " 'end',\n",
       " 'Say',\n",
       " 'it',\n",
       " 'once',\n",
       " 'again',\n",
       " 'with',\n",
       " 'feeling',\n",
       " 'How',\n",
       " 'the',\n",
       " 'death',\n",
       " 'rattle',\n",
       " 'breathing',\n",
       " 'Silenced',\n",
       " 'as',\n",
       " 'the',\n",
       " 'soul',\n",
       " 'was',\n",
       " 'leaving',\n",
       " 'The',\n",
       " 'deflation',\n",
       " 'of',\n",
       " 'our',\n",
       " 'dreaming',\n",
       " 'Leaving',\n",
       " 'me',\n",
       " 'bereft',\n",
       " 'and',\n",
       " 'reeling',\n",
       " 'My',\n",
       " 'beloved',\n",
       " 'ghost',\n",
       " 'and',\n",
       " 'me',\n",
       " 'Sitting',\n",
       " 'in',\n",
       " 'a',\n",
       " 'tree',\n",
       " 'DYING',\n",
       " \"It's\",\n",
       " \"happenin'\",\n",
       " 'again',\n",
       " 'How',\n",
       " 'did',\n",
       " 'it',\n",
       " 'end',\n",
       " 'I',\n",
       " \"can't\",\n",
       " 'pretend',\n",
       " 'like',\n",
       " 'I',\n",
       " 'understand',\n",
       " 'How',\n",
       " 'did',\n",
       " 'it',\n",
       " 'end',\n",
       " 'Come',\n",
       " 'one',\n",
       " 'come',\n",
       " 'all',\n",
       " \"it's\",\n",
       " \"happenin'\",\n",
       " 'again',\n",
       " 'The',\n",
       " 'empathetic',\n",
       " 'hunger',\n",
       " 'descends',\n",
       " \"We'll\",\n",
       " 'tell',\n",
       " 'no',\n",
       " 'one',\n",
       " 'except',\n",
       " 'all',\n",
       " 'of',\n",
       " 'our',\n",
       " 'friends',\n",
       " 'But',\n",
       " 'I',\n",
       " 'still',\n",
       " \"don't\",\n",
       " 'know',\n",
       " 'How',\n",
       " 'did',\n",
       " 'it',\n",
       " 'end']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs.words[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "33073286-407c-4011-a2d6-d770e44e1d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "songs.words = songs.words.apply(lambda words: [word.lower() for word in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2c7b4356-2599-4aff-b6e1-18961e781e67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>album</th>\n",
       "      <th>song</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.TTPD</td>\n",
       "      <td>HowDidItEnd</td>\n",
       "      <td>\\n(Uh-oh, uh-oh)\\n\\n\\nWe hereby conduct this p...</td>\n",
       "      <td>[uhoh, uhoh, we, hereby, conduct, this, postmo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.TTPD</td>\n",
       "      <td>TheBolter</td>\n",
       "      <td>\\nBy all accounts, she almost drowned\\nWhen sh...</td>\n",
       "      <td>[by, all, accounts, she, almost, drowned, when...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.TTPD</td>\n",
       "      <td>Peter</td>\n",
       "      <td>\\nForgive me, Peter\\nMy lost fearless leader\\n...</td>\n",
       "      <td>[forgive, me, peter, my, lost, fearless, leade...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.TTPD</td>\n",
       "      <td>imgonnagetyouback</td>\n",
       "      <td>\\nYeah\\n\\n\\nLilac short skirt, the one that fi...</td>\n",
       "      <td>[yeah, lilac, short, skirt, the, one, that, fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.TTPD</td>\n",
       "      <td>DownBad</td>\n",
       "      <td>\\nDid you really beam me up\\nIn a cloud of spa...</td>\n",
       "      <td>[did, you, really, beam, me, up, in, a, cloud,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>7.Lover</td>\n",
       "      <td>MissAmericanaTheHeartbreakPrince</td>\n",
       "      <td>\\nYou know I adore you, I'm crazier for you\\nT...</td>\n",
       "      <td>[you, know, i, adore, you, i'm, crazier, for, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>7.Lover</td>\n",
       "      <td>CruelSummer</td>\n",
       "      <td>\\n(Yeah, yeah, yeah, yeah)\\n\\n\\nFever dream hi...</td>\n",
       "      <td>[yeah, yeah, yeah, yeah, fever, dream, high, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>7.Lover</td>\n",
       "      <td>LondonBoy</td>\n",
       "      <td>\\nWe can go drivin' in, on my scooter\\nUh, you...</td>\n",
       "      <td>[we, can, go, drivin', in, on, my, scooter, uh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>7.Lover</td>\n",
       "      <td>FalseGod</td>\n",
       "      <td>\\nWe were crazy to think\\nCrazy to think that ...</td>\n",
       "      <td>[we, were, crazy, to, think, crazy, to, think,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>7.Lover</td>\n",
       "      <td>IThinkHeKnows</td>\n",
       "      <td>\\nI think he knows\\nHis footprints on the side...</td>\n",
       "      <td>[i, think, he, knows, his, footprints, on, the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>242 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       album                              song  \\\n",
       "0    11.TTPD                       HowDidItEnd   \n",
       "1    11.TTPD                         TheBolter   \n",
       "2    11.TTPD                             Peter   \n",
       "3    11.TTPD                 imgonnagetyouback   \n",
       "4    11.TTPD                           DownBad   \n",
       "..       ...                               ...   \n",
       "238  7.Lover  MissAmericanaTheHeartbreakPrince   \n",
       "239  7.Lover                       CruelSummer   \n",
       "240  7.Lover                         LondonBoy   \n",
       "241  7.Lover                          FalseGod   \n",
       "242  7.Lover                     IThinkHeKnows   \n",
       "\n",
       "                                                lyrics  \\\n",
       "0    \\n(Uh-oh, uh-oh)\\n\\n\\nWe hereby conduct this p...   \n",
       "1    \\nBy all accounts, she almost drowned\\nWhen sh...   \n",
       "2    \\nForgive me, Peter\\nMy lost fearless leader\\n...   \n",
       "3    \\nYeah\\n\\n\\nLilac short skirt, the one that fi...   \n",
       "4    \\nDid you really beam me up\\nIn a cloud of spa...   \n",
       "..                                                 ...   \n",
       "238  \\nYou know I adore you, I'm crazier for you\\nT...   \n",
       "239  \\n(Yeah, yeah, yeah, yeah)\\n\\n\\nFever dream hi...   \n",
       "240  \\nWe can go drivin' in, on my scooter\\nUh, you...   \n",
       "241  \\nWe were crazy to think\\nCrazy to think that ...   \n",
       "242  \\nI think he knows\\nHis footprints on the side...   \n",
       "\n",
       "                                                 words  \n",
       "0    [uhoh, uhoh, we, hereby, conduct, this, postmo...  \n",
       "1    [by, all, accounts, she, almost, drowned, when...  \n",
       "2    [forgive, me, peter, my, lost, fearless, leade...  \n",
       "3    [yeah, lilac, short, skirt, the, one, that, fi...  \n",
       "4    [did, you, really, beam, me, up, in, a, cloud,...  \n",
       "..                                                 ...  \n",
       "238  [you, know, i, adore, you, i'm, crazier, for, ...  \n",
       "239  [yeah, yeah, yeah, yeah, fever, dream, high, i...  \n",
       "240  [we, can, go, drivin', in, on, my, scooter, uh...  \n",
       "241  [we, were, crazy, to, think, crazy, to, think,...  \n",
       "242  [i, think, he, knows, his, footprints, on, the...  \n",
       "\n",
       "[242 rows x 4 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8a5a60bb-1649-4050-9849-2ac80f6bd891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['uhoh',\n",
       " 'uhoh',\n",
       " 'we',\n",
       " 'hereby',\n",
       " 'conduct',\n",
       " 'this',\n",
       " 'postmortem',\n",
       " 'he',\n",
       " 'was',\n",
       " 'a',\n",
       " 'hot',\n",
       " 'house',\n",
       " 'flower',\n",
       " 'to',\n",
       " 'my',\n",
       " 'outdoorsman',\n",
       " 'our',\n",
       " 'maladies',\n",
       " 'were',\n",
       " 'such',\n",
       " 'we',\n",
       " 'could',\n",
       " 'not',\n",
       " 'cure',\n",
       " 'them',\n",
       " 'and',\n",
       " 'so',\n",
       " 'a',\n",
       " 'touch',\n",
       " 'that',\n",
       " 'was',\n",
       " 'my',\n",
       " 'birthright',\n",
       " 'became',\n",
       " 'foreign',\n",
       " 'come',\n",
       " 'one',\n",
       " 'come',\n",
       " 'all',\n",
       " \"it's\",\n",
       " \"happenin'\",\n",
       " 'again',\n",
       " 'the',\n",
       " 'empathetic',\n",
       " 'hunger',\n",
       " 'descends',\n",
       " \"we'll\",\n",
       " 'tell',\n",
       " 'no',\n",
       " 'one',\n",
       " 'except',\n",
       " 'all',\n",
       " 'of',\n",
       " 'our',\n",
       " 'friends',\n",
       " 'we',\n",
       " 'must',\n",
       " 'know',\n",
       " 'how',\n",
       " 'did',\n",
       " 'it',\n",
       " 'end',\n",
       " 'uhoh',\n",
       " 'uhoh',\n",
       " 'we',\n",
       " 'were',\n",
       " 'blind',\n",
       " 'to',\n",
       " 'unforeseen',\n",
       " 'circumstances',\n",
       " 'we',\n",
       " 'learned',\n",
       " 'thе',\n",
       " 'right',\n",
       " 'steps',\n",
       " 'to',\n",
       " 'different',\n",
       " 'dancеs',\n",
       " 'and',\n",
       " 'fell',\n",
       " 'victim',\n",
       " 'to',\n",
       " \"interlopers'\",\n",
       " 'glances',\n",
       " 'lost',\n",
       " 'the',\n",
       " 'game',\n",
       " 'of',\n",
       " 'chance',\n",
       " 'what',\n",
       " 'are',\n",
       " 'the',\n",
       " 'chances',\n",
       " 'soon',\n",
       " \"they'll\",\n",
       " 'go',\n",
       " 'home',\n",
       " 'to',\n",
       " 'their',\n",
       " 'husbands',\n",
       " 'smug',\n",
       " \"'cause\",\n",
       " 'they',\n",
       " 'know',\n",
       " 'they',\n",
       " 'can',\n",
       " 'trust',\n",
       " 'him',\n",
       " 'then',\n",
       " 'feverishly',\n",
       " 'calling',\n",
       " 'their',\n",
       " 'cousins',\n",
       " 'see',\n",
       " 'taylor',\n",
       " 'swift',\n",
       " 'liveget',\n",
       " 'tickets',\n",
       " 'as',\n",
       " 'low',\n",
       " 'as',\n",
       " '$60you',\n",
       " 'might',\n",
       " 'also',\n",
       " 'like',\n",
       " 'guess',\n",
       " 'who',\n",
       " 'we',\n",
       " 'ran',\n",
       " 'into',\n",
       " 'at',\n",
       " 'the',\n",
       " 'shops',\n",
       " 'walking',\n",
       " 'in',\n",
       " 'circles',\n",
       " 'like',\n",
       " 'she',\n",
       " 'was',\n",
       " 'lost',\n",
       " \"didn't\",\n",
       " 'you',\n",
       " 'hear',\n",
       " 'they',\n",
       " 'called',\n",
       " 'it',\n",
       " 'all',\n",
       " 'off',\n",
       " 'one',\n",
       " 'gasp',\n",
       " 'and',\n",
       " 'then',\n",
       " 'how',\n",
       " 'did',\n",
       " 'it',\n",
       " 'end',\n",
       " 'say',\n",
       " 'it',\n",
       " 'once',\n",
       " 'again',\n",
       " 'with',\n",
       " 'feeling',\n",
       " 'how',\n",
       " 'the',\n",
       " 'death',\n",
       " 'rattle',\n",
       " 'breathing',\n",
       " 'silenced',\n",
       " 'as',\n",
       " 'the',\n",
       " 'soul',\n",
       " 'was',\n",
       " 'leaving',\n",
       " 'the',\n",
       " 'deflation',\n",
       " 'of',\n",
       " 'our',\n",
       " 'dreaming',\n",
       " 'leaving',\n",
       " 'me',\n",
       " 'bereft',\n",
       " 'and',\n",
       " 'reeling',\n",
       " 'my',\n",
       " 'beloved',\n",
       " 'ghost',\n",
       " 'and',\n",
       " 'me',\n",
       " 'sitting',\n",
       " 'in',\n",
       " 'a',\n",
       " 'tree',\n",
       " 'dying',\n",
       " \"it's\",\n",
       " \"happenin'\",\n",
       " 'again',\n",
       " 'how',\n",
       " 'did',\n",
       " 'it',\n",
       " 'end',\n",
       " 'i',\n",
       " \"can't\",\n",
       " 'pretend',\n",
       " 'like',\n",
       " 'i',\n",
       " 'understand',\n",
       " 'how',\n",
       " 'did',\n",
       " 'it',\n",
       " 'end',\n",
       " 'come',\n",
       " 'one',\n",
       " 'come',\n",
       " 'all',\n",
       " \"it's\",\n",
       " \"happenin'\",\n",
       " 'again',\n",
       " 'the',\n",
       " 'empathetic',\n",
       " 'hunger',\n",
       " 'descends',\n",
       " \"we'll\",\n",
       " 'tell',\n",
       " 'no',\n",
       " 'one',\n",
       " 'except',\n",
       " 'all',\n",
       " 'of',\n",
       " 'our',\n",
       " 'friends',\n",
       " 'but',\n",
       " 'i',\n",
       " 'still',\n",
       " \"don't\",\n",
       " 'know',\n",
       " 'how',\n",
       " 'did',\n",
       " 'it',\n",
       " 'end']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs.words[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7d74d813-96e5-48ee-ad31-49231a49b58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = stopwords.words('english').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cea1ac4a-3722-4c05-b2a1-448de3ead2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "bonus_words = ['uhoh','we\\'ll','ooh','radidididididididididada','yeah','woah']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cd392d13-0335-4341-aa71-517b8eb5ce58",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in bonus_words:\n",
    "    stopwords.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "226d71fa-e0fd-4d41-87ab-d28dd5fbae7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'uhoh',\n",
       " \"we'll\",\n",
       " 'ooh',\n",
       " 'radidididididididididada',\n",
       " 'yeah',\n",
       " 'woah']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "39f05182-df0f-4d03-b0d6-6f20299b1010",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_no_stop = [word for word in songs.words[0] if word not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2800dd63-5035-4313-8021-e8cf646adad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hereby',\n",
       " 'conduct',\n",
       " 'postmortem',\n",
       " 'hot',\n",
       " 'house',\n",
       " 'flower',\n",
       " 'outdoorsman',\n",
       " 'maladies',\n",
       " 'could',\n",
       " 'cure',\n",
       " 'touch',\n",
       " 'birthright',\n",
       " 'became',\n",
       " 'foreign',\n",
       " 'come',\n",
       " 'one',\n",
       " 'come',\n",
       " \"happenin'\",\n",
       " 'empathetic',\n",
       " 'hunger',\n",
       " 'descends',\n",
       " 'tell',\n",
       " 'one',\n",
       " 'except',\n",
       " 'friends',\n",
       " 'must',\n",
       " 'know',\n",
       " 'end',\n",
       " 'blind',\n",
       " 'unforeseen',\n",
       " 'circumstances',\n",
       " 'learned',\n",
       " 'thе',\n",
       " 'right',\n",
       " 'steps',\n",
       " 'different',\n",
       " 'dancеs',\n",
       " 'fell',\n",
       " 'victim',\n",
       " \"interlopers'\",\n",
       " 'glances',\n",
       " 'lost',\n",
       " 'game',\n",
       " 'chance',\n",
       " 'chances',\n",
       " 'soon',\n",
       " \"they'll\",\n",
       " 'go',\n",
       " 'home',\n",
       " 'husbands',\n",
       " 'smug',\n",
       " \"'cause\",\n",
       " 'know',\n",
       " 'trust',\n",
       " 'feverishly',\n",
       " 'calling',\n",
       " 'cousins',\n",
       " 'see',\n",
       " 'taylor',\n",
       " 'swift',\n",
       " 'liveget',\n",
       " 'tickets',\n",
       " 'low',\n",
       " '$60you',\n",
       " 'might',\n",
       " 'also',\n",
       " 'like',\n",
       " 'guess',\n",
       " 'ran',\n",
       " 'shops',\n",
       " 'walking',\n",
       " 'circles',\n",
       " 'like',\n",
       " 'lost',\n",
       " 'hear',\n",
       " 'called',\n",
       " 'one',\n",
       " 'gasp',\n",
       " 'end',\n",
       " 'say',\n",
       " 'feeling',\n",
       " 'death',\n",
       " 'rattle',\n",
       " 'breathing',\n",
       " 'silenced',\n",
       " 'soul',\n",
       " 'leaving',\n",
       " 'deflation',\n",
       " 'dreaming',\n",
       " 'leaving',\n",
       " 'bereft',\n",
       " 'reeling',\n",
       " 'beloved',\n",
       " 'ghost',\n",
       " 'sitting',\n",
       " 'tree',\n",
       " 'dying',\n",
       " \"happenin'\",\n",
       " 'end',\n",
       " \"can't\",\n",
       " 'pretend',\n",
       " 'like',\n",
       " 'understand',\n",
       " 'end',\n",
       " 'come',\n",
       " 'one',\n",
       " 'come',\n",
       " \"happenin'\",\n",
       " 'empathetic',\n",
       " 'hunger',\n",
       " 'descends',\n",
       " 'tell',\n",
       " 'one',\n",
       " 'except',\n",
       " 'friends',\n",
       " 'still',\n",
       " 'know',\n",
       " 'end']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_no_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1136bd65-41e1-478f-a8ad-389be3ce81b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "songs.words = songs.words.apply(lambda words: [word for word in words if word not in stopwords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b49ffd68-6b5e-40a4-8085-56facfa9cbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "67ed55f7-c856-4e68-aa5f-a23b06c3cb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_lematized = [lemmatizer.lemmatize(word) for word in words_no_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0422750c-fbba-4893-9f1a-e9013c466768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hereby',\n",
       " 'conduct',\n",
       " 'postmortem',\n",
       " 'hot',\n",
       " 'house',\n",
       " 'flower',\n",
       " 'outdoorsman',\n",
       " 'malady',\n",
       " 'could',\n",
       " 'cure',\n",
       " 'touch',\n",
       " 'birthright',\n",
       " 'became',\n",
       " 'foreign',\n",
       " 'come',\n",
       " 'one',\n",
       " 'come',\n",
       " \"happenin'\",\n",
       " 'empathetic',\n",
       " 'hunger',\n",
       " 'descends',\n",
       " 'tell',\n",
       " 'one',\n",
       " 'except',\n",
       " 'friend',\n",
       " 'must',\n",
       " 'know',\n",
       " 'end',\n",
       " 'blind',\n",
       " 'unforeseen',\n",
       " 'circumstance',\n",
       " 'learned',\n",
       " 'thе',\n",
       " 'right',\n",
       " 'step',\n",
       " 'different',\n",
       " 'dancеs',\n",
       " 'fell',\n",
       " 'victim',\n",
       " \"interlopers'\",\n",
       " 'glance',\n",
       " 'lost',\n",
       " 'game',\n",
       " 'chance',\n",
       " 'chance',\n",
       " 'soon',\n",
       " \"they'll\",\n",
       " 'go',\n",
       " 'home',\n",
       " 'husband',\n",
       " 'smug',\n",
       " \"'cause\",\n",
       " 'know',\n",
       " 'trust',\n",
       " 'feverishly',\n",
       " 'calling',\n",
       " 'cousin',\n",
       " 'see',\n",
       " 'taylor',\n",
       " 'swift',\n",
       " 'liveget',\n",
       " 'ticket',\n",
       " 'low',\n",
       " '$60you',\n",
       " 'might',\n",
       " 'also',\n",
       " 'like',\n",
       " 'guess',\n",
       " 'ran',\n",
       " 'shop',\n",
       " 'walking',\n",
       " 'circle',\n",
       " 'like',\n",
       " 'lost',\n",
       " 'hear',\n",
       " 'called',\n",
       " 'one',\n",
       " 'gasp',\n",
       " 'end',\n",
       " 'say',\n",
       " 'feeling',\n",
       " 'death',\n",
       " 'rattle',\n",
       " 'breathing',\n",
       " 'silenced',\n",
       " 'soul',\n",
       " 'leaving',\n",
       " 'deflation',\n",
       " 'dreaming',\n",
       " 'leaving',\n",
       " 'bereft',\n",
       " 'reeling',\n",
       " 'beloved',\n",
       " 'ghost',\n",
       " 'sitting',\n",
       " 'tree',\n",
       " 'dying',\n",
       " \"happenin'\",\n",
       " 'end',\n",
       " \"can't\",\n",
       " 'pretend',\n",
       " 'like',\n",
       " 'understand',\n",
       " 'end',\n",
       " 'come',\n",
       " 'one',\n",
       " 'come',\n",
       " \"happenin'\",\n",
       " 'empathetic',\n",
       " 'hunger',\n",
       " 'descends',\n",
       " 'tell',\n",
       " 'one',\n",
       " 'except',\n",
       " 'friend',\n",
       " 'still',\n",
       " 'know',\n",
       " 'end']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_lematized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0647eff8-84c0-440e-ac9a-267354889f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "songs.words = songs.words.apply(lambda words: [lemmatizer.lemmatize(word) for word in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "66dd2306-b8e0-4a08-8092-d02eac7bb781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>album</th>\n",
       "      <th>song</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.TTPD</td>\n",
       "      <td>HowDidItEnd</td>\n",
       "      <td>\\n(Uh-oh, uh-oh)\\n\\n\\nWe hereby conduct this p...</td>\n",
       "      <td>[hereby, conduct, postmortem, hot, house, flow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.TTPD</td>\n",
       "      <td>TheBolter</td>\n",
       "      <td>\\nBy all accounts, she almost drowned\\nWhen sh...</td>\n",
       "      <td>[account, almost, drowned, six, frigid, water,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.TTPD</td>\n",
       "      <td>Peter</td>\n",
       "      <td>\\nForgive me, Peter\\nMy lost fearless leader\\n...</td>\n",
       "      <td>[forgive, peter, lost, fearless, leader, close...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.TTPD</td>\n",
       "      <td>imgonnagetyouback</td>\n",
       "      <td>\\nYeah\\n\\n\\nLilac short skirt, the one that fi...</td>\n",
       "      <td>[lilac, short, skirt, one, fit, like, skin, re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.TTPD</td>\n",
       "      <td>DownBad</td>\n",
       "      <td>\\nDid you really beam me up\\nIn a cloud of spa...</td>\n",
       "      <td>[really, beam, cloud, sparkling, dust, experim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>7.Lover</td>\n",
       "      <td>MissAmericanaTheHeartbreakPrince</td>\n",
       "      <td>\\nYou know I adore you, I'm crazier for you\\nT...</td>\n",
       "      <td>[know, adore, i'm, crazier, 16, lost, film, sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>7.Lover</td>\n",
       "      <td>CruelSummer</td>\n",
       "      <td>\\n(Yeah, yeah, yeah, yeah)\\n\\n\\nFever dream hi...</td>\n",
       "      <td>[fever, dream, high, quiet, night, know, caugh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>7.Lover</td>\n",
       "      <td>LondonBoy</td>\n",
       "      <td>\\nWe can go drivin' in, on my scooter\\nUh, you...</td>\n",
       "      <td>[go, drivin', scooter, uh, know, 'round, londo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>7.Lover</td>\n",
       "      <td>FalseGod</td>\n",
       "      <td>\\nWe were crazy to think\\nCrazy to think that ...</td>\n",
       "      <td>[crazy, think, crazy, think, could, work, reme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>7.Lover</td>\n",
       "      <td>IThinkHeKnows</td>\n",
       "      <td>\\nI think he knows\\nHis footprints on the side...</td>\n",
       "      <td>[think, know, footprint, sidewalk, lead, can't...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>242 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       album                              song  \\\n",
       "0    11.TTPD                       HowDidItEnd   \n",
       "1    11.TTPD                         TheBolter   \n",
       "2    11.TTPD                             Peter   \n",
       "3    11.TTPD                 imgonnagetyouback   \n",
       "4    11.TTPD                           DownBad   \n",
       "..       ...                               ...   \n",
       "238  7.Lover  MissAmericanaTheHeartbreakPrince   \n",
       "239  7.Lover                       CruelSummer   \n",
       "240  7.Lover                         LondonBoy   \n",
       "241  7.Lover                          FalseGod   \n",
       "242  7.Lover                     IThinkHeKnows   \n",
       "\n",
       "                                                lyrics  \\\n",
       "0    \\n(Uh-oh, uh-oh)\\n\\n\\nWe hereby conduct this p...   \n",
       "1    \\nBy all accounts, she almost drowned\\nWhen sh...   \n",
       "2    \\nForgive me, Peter\\nMy lost fearless leader\\n...   \n",
       "3    \\nYeah\\n\\n\\nLilac short skirt, the one that fi...   \n",
       "4    \\nDid you really beam me up\\nIn a cloud of spa...   \n",
       "..                                                 ...   \n",
       "238  \\nYou know I adore you, I'm crazier for you\\nT...   \n",
       "239  \\n(Yeah, yeah, yeah, yeah)\\n\\n\\nFever dream hi...   \n",
       "240  \\nWe can go drivin' in, on my scooter\\nUh, you...   \n",
       "241  \\nWe were crazy to think\\nCrazy to think that ...   \n",
       "242  \\nI think he knows\\nHis footprints on the side...   \n",
       "\n",
       "                                                 words  \n",
       "0    [hereby, conduct, postmortem, hot, house, flow...  \n",
       "1    [account, almost, drowned, six, frigid, water,...  \n",
       "2    [forgive, peter, lost, fearless, leader, close...  \n",
       "3    [lilac, short, skirt, one, fit, like, skin, re...  \n",
       "4    [really, beam, cloud, sparkling, dust, experim...  \n",
       "..                                                 ...  \n",
       "238  [know, adore, i'm, crazier, 16, lost, film, sc...  \n",
       "239  [fever, dream, high, quiet, night, know, caugh...  \n",
       "240  [go, drivin', scooter, uh, know, 'round, londo...  \n",
       "241  [crazy, think, crazy, think, could, work, reme...  \n",
       "242  [think, know, footprint, sidewalk, lead, can't...  \n",
       "\n",
       "[242 rows x 4 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df34c382-b3ce-4c98-a127-0c92ffa94a5c",
   "metadata": {},
   "source": [
    "Some models require passing of a string because they have an internal tokenization and trimming process. Thats why I am also going to save the processed words as text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "32d6b856-73e7-4308-848a-af61f04e7789",
   "metadata": {},
   "outputs": [],
   "source": [
    "songs['joined_words'] = songs.words.apply(lambda words: \" \".join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e6726e59-4da8-45f8-816e-0be25a6ee403",
   "metadata": {},
   "outputs": [],
   "source": [
    "songs[['album','song','words','joined_words']].to_csv(\"../data/results/processed_lyrics\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134d11ae-4d62-4365-adb0-38a202dd0890",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
